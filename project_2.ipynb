{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Market Segmentation Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pkg_resources\n",
    "\n",
    "vaccsv = pkg_resources.resource_filename(\"MSA\", \"csv/mcdonald.csv\")\n",
    "shutil.copy(vaccsv, \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vac = pd.read_csv(\"mcdonalds.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colnames = vac.columns.tolist()\n",
    "dim = vac.shape\n",
    "\n",
    "print(\"Column names:\")\n",
    "for col in colnames:\n",
    "    print(col)\n",
    "\n",
    "print(\"Dimensions:\")\n",
    "print(dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subset_cols = [\"like\", \"Age\", \"frequency_visited\", \"gender\"]\n",
    "subset = vac[subset_cols]\n",
    "\n",
    "summary = subset.describe(include=\"all\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inc2 = vac[\"like\"]\n",
    "\n",
    "levels = inc2.unique()\n",
    "print(\"Levels:\")\n",
    "print(levels)\n",
    "\n",
    "lev = [\"ummy\",\"convenient\",\"spicy\",\"fattening\",\"greasy\",\"fast\",\"cheap\",\"tasty\",\"expensive\",\"healthy\",\"disgusting\"]\n",
    "inc2 = pd.Categorical(inc2, categories=lev, ordered=True)\n",
    "\n",
    "print(\"Updated inc2:\")\n",
    "print(inc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(vac[\"Age\"], bins=10)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Age\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vac = pd.read_csv(\"vacation.csv\")\n",
    "\n",
    "plt.hist(vac[\"Age\"], bins=50, density=True)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Histogram of Age\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "age_summary = vac[\"Age\"].describe()\n",
    "\n",
    "print(\"Summary of Age:\")\n",
    "print(age_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.boxplot(vac[\"Age\"], vert=False)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yes = 100 * (vac.iloc[:, 0:11] == \"yes\").mean()\n",
    "sorted_yes = yes.sort_values()\n",
    "\n",
    "plt.scatter(sorted_yes, range(len(sorted_yes)))\n",
    "plt.xlabel(\"Percent 'yes'\")\n",
    "plt.xlim(0, 100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "like_counts = vac[\"like\"].value_counts().sort_index()\n",
    "\n",
    "print(\"Sorted Income Counts:\")\n",
    "print(like_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vacmot = (vac.iloc[:, 0:11] == \"yes\").astype(int)\n",
    "\n",
    "print(\"vacmot DataFrame:\")\n",
    "print(vacmot)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUMERICAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "vacmot_scaled = StandardScaler().fit_transform(vacmot)\n",
    "\n",
    "print(\"vacmot_scaled array:\")\n",
    "print(vacmot_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "vacmot_pca = pca.fit_transform(vacmot)\n",
    "\n",
    "print(\"vacmot_pca array:\")\n",
    "print(vacmot_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary of vacmot_pca:\")\n",
    "print(\"Standard deviations:\")\n",
    "print(pca.explained_variance_)\n",
    "print(\"Proportion of variance:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"Cumulative proportion of variance:\")\n",
    "print(np.cumsum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "vacmot_pca = pca.fit_transform(vacmot)\n",
    "\n",
    "plt.scatter(vacmot_pca[:, 1], vacmot_pca[:, 2], marker='o', color='grey', edgecolors='black')\n",
    "plt.xlabel(\"PC2\")\n",
    "plt.ylabel(\"PC3\")\n",
    "plt.title(\"Projection Axes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Extracting Segments\n",
    "1)\tDistance-Based Methods\n",
    "i)\tDistance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "annabill = fetch_openml(name=\"annabill\", as_frame=True)\n",
    "\n",
    "print(\"annabill DataFrame:\")\n",
    "print(annabill.data)\n",
    "print(\"Target variable:\")\n",
    "print(annabill.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Assuming annabill.data contains the input features\n",
    "D1 = euclidean_distances(annabill.data)\n",
    "\n",
    "rounded_D1 = D1.round(2)\n",
    "\n",
    "print(\"Distance matrix:\")\n",
    "print(rounded_D1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "# Assuming annabill.data contains the input features\n",
    "D2 = manhattan_distances(annabill.data)\n",
    "\n",
    "print(\"Distance matrix:\")\n",
    "print(D2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "D2_matrix = np.array(D2)\n",
    "\n",
    "print(\"Distance matrix as a matrix:\")\n",
    "print(D2_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "\n",
    "annabill = fetch_openml(name=\"annabill\", as_frame=True)\n",
    "\n",
    "# Assuming annabill.data contains the input features\n",
    "dissimilarity_matrix = pairwise_distances(annabill.data, metric=\"euclidean\")\n",
    "\n",
    "rounded_dissimilarity_matrix = np.round(dissimilarity_matrix, decimals=2)\n",
    "\n",
    "print(\"Dissimilarity matrix:\")\n",
    "print(rounded_dissimilarity_matrix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii)\tHierarchical Methods\n",
    "\n",
    "Example: Tourist Risk Taking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "risk = fetch_openml(name=\"risk\", as_frame=True)\n",
    "\n",
    "# Assuming risk.data contains the input features\n",
    "data_shape = risk.data.shape\n",
    "\n",
    "print(\"Dimensions of the 'risk' dataset:\")\n",
    "print(data_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming risk.data contains the input features\n",
    "col_means = np.mean(risk.data, axis=0)\n",
    "\n",
    "print(\"Column means:\")\n",
    "print(col_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming risk.data contains the input features\n",
    "risk_dist = pdist(risk.data, metric=\"cityblock\")\n",
    "risk_hcl = linkage(risk_dist, method=\"complete\")\n",
    "\n",
    "print(\"Hierarchical clustering object:\")\n",
    "print(risk_hcl)\n",
    "\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "dendrogram(risk_hcl)\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import cut_tree\n",
    "\n",
    "# Assuming risk.hcl contains the hierarchical clustering object\n",
    "c2 = cut_tree(risk_hcl, h=20)\n",
    "cluster_counts = np.squeeze(np.bincount(np.squeeze(c2)))\n",
    "\n",
    "print(\"Cluster counts:\")\n",
    "print(cluster_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import cut_tree\n",
    "\n",
    "# Assuming risk.hcl contains the hierarchical clustering object\n",
    "c6 = cut_tree(risk_hcl, n_clusters=[6])\n",
    "cluster_counts = np.squeeze(np.bincount(np.squeeze(c6)))\n",
    "\n",
    "print(\"Cluster counts:\")\n",
    "print(cluster_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming risk.data contains the input features\n",
    "c6_means = pd.DataFrame(risk.data).groupby(c6[:, 0]).mean().round(1)\n",
    "c6_means.columns = risk.colnames\n",
    "\n",
    "print(\"Cluster means:\")\n",
    "print(c6_means)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii)\tPartitioning Method\n",
    "Example: Artificial Mobile Phone Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Generate synthetic dataset with 500 samples and 3 clusters\n",
    "PF3, _ = make_blobs(n_samples=500, centers=3, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Perform k-means clustering with k = 3\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=1234)\n",
    "PF3_km3 = kmeans.fit_predict(PF3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "# Get cluster assignments for the first 20 samples\n",
    "cluster_assignments = kmeans.labels_[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "# Perform k-means clustering with k = 3\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=1234)\n",
    "cluster_assignments = kmeans.fit_predict(PF3)\n",
    "\n",
    "# Plot the data points colored by cluster\n",
    "plt.scatter(PF3[:, 0], PF3[:, 1], c=cluster_assignments)\n",
    "\n",
    "# Compute and plot the convex hulls for each cluster\n",
    "for cluster_id in range(k):\n",
    "    cluster_points = PF3[cluster_assignments == cluster_id]\n",
    "    hull = ConvexHull(cluster_points)\n",
    "    for simplex in hull.simplices:\n",
    "        plt.plot(cluster_points[simplex, 0], cluster_points[simplex, 1], 'k--')\n",
    "\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('performance / quality price')\n",
    "plt.title('Cluster Hulls')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Tourist Risk Taking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "PF3 = np.array(PF3)  # Convert PF3 to a numpy array\n",
    "\n",
    "# Define the range of cluster numbers to consider\n",
    "k_range = range(2, 9)\n",
    "\n",
    "# Initialize variables to store results\n",
    "dist_sum = []\n",
    "converged = []\n",
    "iterations = []\n",
    "\n",
    "# Perform stepwise clustering\n",
    "for k in k_range:\n",
    "    # Repeat clustering 10 times and select the best result based on inertia\n",
    "    best_inertia = np.inf\n",
    "    best_cluster_assignments = None\n",
    "    for _ in range(10):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=1234)\n",
    "        cluster_assignments = kmeans.fit_predict(PF3)\n",
    "        inertia = kmeans.inertia_\n",
    "        if inertia < best_inertia:\n",
    "            best_inertia = inertia\n",
    "            best_cluster_assignments = cluster_assignments\n",
    "    \n",
    "    # Store the results\n",
    "    dist_sum.append(best_inertia)\n",
    "    converged.append(True)\n",
    "    iterations.append(None)\n",
    "\n",
    "# Print the results\n",
    "for i, k in enumerate(k_range):\n",
    "    print(f\"{k} : {dist_sum[i]} {converged[i]} {iterations[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Retrieve the cluster assignments for k=2 from risk.km28\n",
    "cluster_assignments = risk.km28.cluster\n",
    "\n",
    "# Count the number of instances in each cluster\n",
    "cluster_counts = np.bincount(cluster_assignments)\n",
    "\n",
    "# Create a bar chart\n",
    "plt.bar(range(2), cluster_counts)\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Cluster Counts for k=2')\n",
    "plt.xticks(range(2))\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-Organising Maps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from minisom import MiniSom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Define the SOM grid size\n",
    "grid_size = (5, 5)\n",
    "\n",
    "# Create the SOM object\n",
    "som = MiniSom(grid_size[0], grid_size[1], len(risk.columns), sigma=1.0, learning_rate=0.5)\n",
    "\n",
    "# Initialize the weights\n",
    "som.random_weights_init(risk.values)\n",
    "\n",
    "# Train the SOM\n",
    "som.train_random(risk.values, 100)\n",
    "\n",
    "# Generate the SOM visualization\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.pcolor(som.distance_map().T, cmap='bone_r')  # Plot the distance map as a background\n",
    "plt.colorbar()\n",
    "\n",
    "# Plot the data points on the SOM grid\n",
    "for i, x in enumerate(risk.values):\n",
    "    w = som.winner(x)  # Find the winning neuron for the data point\n",
    "    plt.plot(w[0] + 0.5, w[1] + 0.5, 'o', markerfacecolor='None', markeredgecolor='red', markersize=10, markeredgewidth=2)\n",
    "\n",
    "plt.title('SOM Visualization')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-Step Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Create the KMeans object\n",
    "kmeans = KMeans(n_clusters=30, random_state=1234)\n",
    "\n",
    "# Fit the data to the KMeans model\n",
    "kmeans.fit(PF3)\n",
    "\n",
    "# Get the cluster labels\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Print the cluster labels for the data points\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming PF3 is your data\n",
    "# Assuming labels is the cluster labels obtained from K-means\n",
    "\n",
    "# Create a scatter plot of the data points colored by cluster labels\n",
    "plt.scatter(PF3[:, 0], PF3[:, 1], c=labels, cmap='viridis')\n",
    "\n",
    "# Add plot labels and title\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Clustering Results')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming PF3 is your data\n",
    "# Assuming PF3.k30 is the clustering result\n",
    "\n",
    "# Get the cluster centers\n",
    "centroids = np.array(PF3.k30.cent)\n",
    "\n",
    "# Get the cluster sizes\n",
    "sizes = np.array(sizes)\n",
    "\n",
    "# Print the cluster centers\n",
    "print(\"Cluster Centers:\")\n",
    "print(centroids)\n",
    "\n",
    "# Print the cluster sizes\n",
    "print(\"Cluster Sizes:\")\n",
    "print(sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming PF3.k30.cent is the cluster centers\n",
    "# Assuming sizes is the cluster sizes\n",
    "\n",
    "# Compute the distance matrix\n",
    "dist_matrix = dist(PF3.k30.cent)\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "hc = linkage(dist_matrix, method='complete', members=sizes)\n",
    "\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "dendrogram(hc)\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.xlabel(\"Clusters\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "\n",
    "# Assuming PF3.hc is the hierarchical clustering result\n",
    "# Assuming clusters(PF3.k30) is the cluster assignments\n",
    "\n",
    "# Create a new AgglomerativeClustering object with linkage='complete'\n",
    "agglomerative = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='complete')\n",
    "\n",
    "# Fit the clustering model with the hierarchical clustering result\n",
    "agglomerative.fit(PF3.hc)\n",
    "\n",
    "# Get the cluster labels\n",
    "cluster_labels = agglomerative.labels_\n",
    "\n",
    "# Compute the cluster sizes\n",
    "cluster_sizes = np.bincount(cluster_labels)\n",
    "\n",
    "# Display the table of cluster sizes\n",
    "table(cluster_sizes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagged Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msa import winterActiv\n",
    "\n",
    "column_names = winterActiv.columns.tolist()\n",
    "print(column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import BinaryKMeans\n",
    "\n",
    "np.random.seed(1234)\n",
    "winter_bc = BinaryKMeans(n_clusters=10, max_iter=50)\n",
    "winter_bc.fit(winterActiv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cluster_labels, cluster_sizes = np.unique(winter_bc.labels_, return_counts=True)\n",
    "\n",
    "plt.bar(cluster_labels, cluster_sizes)\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Cluster Size')\n",
    "plt.title('Cluster Sizes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Create a DataFrame with the data and cluster labels\n",
    "data_with_labels = winter_activ.copy()\n",
    "data_with_labels['Cluster'] = winter_bc.labels_\n",
    "\n",
    "# Specify the order of clusters for plotting\n",
    "cluster_order = range(5)\n",
    "\n",
    "# Create the box plot\n",
    "sns.boxplot(x='Cluster', y=data_with_labels.columns[0], data=data_with_labels, order=cluster_order)\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Variable')\n",
    "plt.title('Box Plot of Variables by Cluster')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Assuming PF3 is your data matrix with shape (n_samples, n_features)\n",
    "G = range(2, 9)  # Range of number of clusters to consider\n",
    "models = [GaussianMixture(n_components=k) for k in G]\n",
    "PF3.m28 = [model.fit(PF3) for model in models]\n",
    "\n",
    "# To access the clustering results for each model\n",
    "for k, model in zip(G, PF3.m28):\n",
    "    print(f\"Number of clusters: {k}\")\n",
    "    print(model.weights_)  # Cluster weights\n",
    "    print(model.means_)  # Cluster means\n",
    "    print(model.covariances_)  # Cluster covariance matrices\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming PF3.m28 is a list of fitted GaussianMixture models\n",
    "G = range(2, 9)  # Range of number of clusters\n",
    "\n",
    "# Calculate the uncertainty measure\n",
    "uncertainty = [model.bic(PF3) for model in PF3.m28]\n",
    "uncertainty = np.array(uncertainty)\n",
    "\n",
    "# Plot the uncertainty measure\n",
    "plt.plot(G, uncertainty, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('BIC')\n",
    "plt.title('Model Uncertainty (BIC)')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Profiling Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, distance\n",
    "\n",
    "# Assuming MD.x is a numpy array of your data\n",
    "MD_vclust = linkage(distance.pdist(np.transpose(MD_x)), method='complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming MD.k4 is a numpy array representing your clustering result\n",
    "# Assuming MD.vclust$order is a numpy array representing the order of bars\n",
    "ordered_clusters = MD_vclust['leaves'][::-1]  # Reverse the order to match R code\n",
    "\n",
    "# Plotting the bar chart with shading\n",
    "plt.bar(range(len(MD_k4)), MD_k4[ordered_clusters], color='grey')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming MD.k4 is a numpy array representing your clustering result\n",
    "# Assuming MD.pca is a numpy array representing the PCA result\n",
    "# Assuming MD.x is a numpy array representing the data points\n",
    "\n",
    "# Plotting the scatter plot\n",
    "plt.scatter(MD.pca[:, 0], MD.pca[:, 1], c=MD.k4)\n",
    "\n",
    "# Plotting projected axes\n",
    "plt.quiver(0, 0, 1, 0, color='r', scale=5)\n",
    "plt.quiver(0, 0, 0, 1, color='b', scale=5)\n",
    "\n",
    "# Setting plot labels\n",
    "plt.xlabel('principal component 1')\n",
    "plt.ylabel('principal component 2')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Describing Segments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming k4 is a numpy array representing the cluster assignments\n",
    "# Assuming mcdonalds is a pandas DataFrame representing the data\n",
    "\n",
    "# Creating a contingency table\n",
    "table = pd.crosstab(k4, mcdonalds['Like'])\n",
    "\n",
    "# Plotting the mosaic plot\n",
    "sns.mosaicplot(table, shade=True)\n",
    "\n",
    "# Setting plot labels\n",
    "plt.xlabel('segment number')\n",
    "plt.ylabel('Like')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming k4 is a numpy array representing the cluster assignments\n",
    "# Assuming mcdonalds is a pandas DataFrame representing the data\n",
    "\n",
    "# Creating a contingency table\n",
    "table = pd.crosstab(k4, mcdonalds['Gender'])\n",
    "\n",
    "# Plotting the mosaic plot\n",
    "sns.mosaicplot(table, shade=True)\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "# Assuming k4 is a numpy array representing the cluster assignments\n",
    "# Assuming mcdonalds is a pandas DataFrame representing the data\n",
    "\n",
    "# Preparing the input features and target variable\n",
    "X = mcdonalds[['Like.n', 'Age', 'VisitFrequency', 'Gender']]\n",
    "y = (k4 == 3).astype(int)\n",
    "\n",
    "# Creating the decision tree model\n",
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X, y)\n",
    "\n",
    "# Visualizing the decision tree\n",
    "dot_data = tree.export_graphviz(tree_model, out_file=None, filled=True, rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree\")  # Save the visualization to a file (optional)\n",
    "graph.view()  # Display the visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming mcdonalds is a pandas DataFrame representing the data\n",
    "\n",
    "# Making predictions using the decision tree model\n",
    "predictions = tree_model.predict(X)\n",
    "\n",
    "# Selecting the target segment(s)\n",
    "target_segment = mcdonalds[predictions == 3]  # Replace '3' with the desired segment(s)\n",
    "\n",
    "# Printing the selected segment(s)\n",
    "print(target_segment)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Selecting (the) Target Segment(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean visit frequency for each segment\n",
    "visit = mcdonalds.groupby(k4)['VisitFrequency'].mean()\n",
    "\n",
    "# Print the mean visit frequency for each segment\n",
    "print(visit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean \"Like.n\" value for each segment\n",
    "like = mcdonalds.groupby(k4)['Like.n'].mean()\n",
    "\n",
    "# Print the mean \"Like.n\" value for each segment\n",
    "print(like)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the proportion of females in each segment\n",
    "female = mcdonalds.groupby(k4)['Gender'].apply(lambda x: (x == 'Female').mean())\n",
    "\n",
    "# Print the proportion of females in each segment\n",
    "print(female)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(visit, like, c=10*female, s=100)\n",
    "\n",
    "# Set the x-axis and y-axis limits\n",
    "plt.xlim(2, 4.5)\n",
    "plt.ylim(-3, 3)\n",
    "\n",
    "# Add text labels for each point\n",
    "for i, (x, y) in enumerate(zip(visit, like)):\n",
    "    plt.text(x, y, i+1)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have variables representing different elements of the marketing mix\n",
    "product_quality = 8\n",
    "price_discount = 0.2\n",
    "promotion_channel = 'online'\n",
    "distribution_coverage = 'national'\n",
    "\n",
    "# Customize the marketing mix based on your goals and strategies\n",
    "if product_quality > 7:\n",
    "    print(\"Enhance product features and quality\")\n",
    "else:\n",
    "    print(\"Focus on improving product quality\")\n",
    "\n",
    "if price_discount > 0.1:\n",
    "    print(\"Offer more attractive discounts to increase sales\")\n",
    "else:\n",
    "    print(\"Consider adjusting pricing strategy\")\n",
    "\n",
    "if promotion_channel == 'online':\n",
    "    print(\"Allocate more resources to online marketing channels\")\n",
    "else:\n",
    "    print(\"Explore additional offline marketing opportunities\")\n",
    "\n",
    "if distribution_coverage == 'national':\n",
    "    print(\"Expand distribution network to reach more regions\")\n",
    "else:\n",
    "    print(\"Optimize existing distribution channels\")\n",
    "\n",
    "# Add more customized marketing mix strategies based on your specific requirements\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9: Customising the Marketing Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_csv(\"mcdonalds.csv\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data.drop(\"Like\", axis=1)\n",
    "y = data[\"Like\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a model (e.g., Logistic Regression)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Perform monitoring tasks (e.g., track key performance indicators)\n",
    "# You can define relevant metrics, thresholds, and tracking mechanisms based on your requirements.\n",
    "\n",
    "# Add more evaluation and monitoring tasks based on your specific needs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
